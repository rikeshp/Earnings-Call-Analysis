{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      title                                            content\n",
      "10  2016_Q2   Clients and Sequoia Shareholders: \\n \\nYou ma...\n",
      "11  2016_Q3   Clients and Shareholders: \\n\\n \\n\\nThe third ...\n",
      "15  2016_Q4   Shareholder: \\n\\nWe completed our most diffic...\n",
      "2   2017_Q1   Shareholder: \\n \\nSequoia Fund generated a 5....\n",
      "1   2017_Q2   Sequoia Shareholders and Clients: \\n\\nSequoia...\n",
      "0   2017_Q3   Sequoia Shareholders and Clients:  \\n\\nSequoi...\n",
      "5   2017_Q4   Sequoia Shareholders and Clients: \\n\\nSequoia...\n",
      "14  2018_Q1   Sequoia Shareholders and Clients:  \\n\\nFor th...\n",
      "12  2018_Q2   Sequoia Shareholders and Clients:  \\n\\nFor th...\n",
      "13  2018_Q3   Sequoia Shareholders and Clients:  \\n\\nFor th...\n",
      "8   2018_Q4   Sequoia Shareholders and Clients:  \\n\\nSequoi...\n",
      "4   2019_Q1   Sequoia Shareholders and Clients:  \\n\\nFor th...\n",
      "7   2019_Q2   Sequoia Shareholders and Clients:  \\n\\nFor th...\n",
      "6   2019_Q3   Sequoia Shareholders and Clients:  \\n\\nFor th...\n",
      "3   2019_Q4   Sequoia Shareholders and Clients:  \\n\\nSequoi...\n",
      "9   2020_Q1   Sequoia Shareholders and Clients:  \\n \\nFor t...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from tika import parser\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import pandas as pd\n",
    "\n",
    "#create dataframe for letter contents\n",
    "files = [i for i in os.listdir(\"SequoiaLetters2\")]\n",
    "letters=[]\n",
    "f_letters=[]\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    letterName = filename.strip('.pdf')\n",
    "    file_data = parser.from_file(file) \n",
    "    text = file_data['content']\n",
    "    #Remove excess words (before and after letter)\n",
    "    split_text = text.split(\"Disclosures\", 1)\n",
    "    text = split_text[0]\n",
    "    split_text2 = text.split(\"Dear\", 1)\n",
    "    text = split_text2[1]\n",
    "    filtered_text = remove_stopwords(text)\n",
    "    letters.append([letterName,text])\n",
    "    f_letters.append([letterName,filtered_text])\n",
    "\n",
    "df= pd.DataFrame(letters, columns=['title','content'])\n",
    "df = df.sort_values('title')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pactiv Corporation ORG\n",
      "Tenneco Automotive ORG\n",
      "Walker ORG\n",
      "Tenneco Automotive ORG\n",
      "Neiman Marcus ORG\n",
      "Chemfirst ORG\n",
      "LNR Corporation ORG\n",
      "Octel ORG\n",
      "Great Lakes Chemical Corporation ORG\n",
      "TEL ORG\n",
      "Octel ORG\n",
      "TEL ORG\n",
      "Stewart Enterprises ORG\n",
      "Ballard Power Systems ORG\n",
      "Saab ORG\n",
      "Saab ORG\n",
      "Celsius ORG\n",
      "Saab ORG\n",
      "Trustor Corporation ORG\n",
      "Maxwell Communications ORG\n",
      "Maxwell ORG\n",
      "The Baupost Fund ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "letter = open(\"baupost1999.txt\",\"r+\")  \n",
    "\n",
    "content = letter.read() \n",
    "content = content.replace('\\n',' ')\n",
    "content = content.replace('\\'','')\n",
    "\n",
    "doc=nlp(content)\n",
    "for ent in doc.ents:\n",
    "    if (ent.label_ == 'ORG'):\n",
    "        print(ent.text,ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner=nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Training examples in the required format\n",
    "TRAIN_DATA =[ (\"Ucar is the world's leading manufacturer of graphite electrodes\", {\"entities\": [(0, 3, \"ORG\")]}),\n",
    "              (\"Chargeurs is a French company which processes and trades in wool and produces fabrics\", {\"entities\": [(0, 9, \"ORG\")]}),\n",
    "              (\"Lambert Fenchurch is a publicly traded insurance broker in the U.K\", {\"entities\": [(0,17, \"ORG\"),(63,65,\"LOC\")]}),\n",
    "              (\"We added to our long position in Dentsply Sirona\", {\"entities\": [(33,47, \"ORG\")]}),\n",
    "              (\"We added to our position in Carmax\", {\"entities\": [(28,34, \"ORG\")]}),\n",
    "              (\"We trimmed our investment in Alphabet\", {\"entities\": [(29,37, \"ORG\")]}),\n",
    "              (\"We bought shares of Amazon\", {\"entities\": [(20,26, \"ORG\")]}),\n",
    "              (\"We purchased Berkshire stocks\", {\"entities\": [(13,22, \"ORG\")]}),\n",
    "              (\"Naspers is a holding company located in South Africa\", {\"entities\": [(0,7, \"ORG\"),(40,52,\"LOC\")]}),\n",
    "              (\"Its principal asset is a large stake in Tencent\", {\"entities\": [(40,47, \"ORG\")]}),\n",
    "              #(\"Tencent operates China's dominant social media platform\", {\"entities\": [(0,7, \"ORG\")]}),\n",
    "              (\"A large interest in U.S cable company Charter Communications\", {\"entities\": [(38,60, \"ORG\"),(20,23,\"LOC\")]}),\n",
    "              (\"We exited our position in Microsoft\", {\"entities\": [(26,35, \"ORG\")]}),\n",
    "              (\"We cut our position in Jacobs Engineering\", {\"entities\": [(23,41, \"ORG\")]})]\n",
    "# Adding labels to the `ner`\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3.1704290667788904e-06}\n",
      "Losses {'ner': 2.033846933192586}\n",
      "Losses {'ner': 2.0340778371316515}\n",
      "Losses {'ner': 2.034077839253342}\n",
      "Losses {'ner': 0.00018190128271990195}\n",
      "Losses {'ner': 0.00018305146507113925}\n",
      "Losses {'ner': 0.00019507853219536238}\n",
      "Losses {'ner': 0.00020651616904710033}\n",
      "Losses {'ner': 0.00021260403033221482}\n",
      "Losses {'ner': 0.00021483141756100706}\n",
      "Losses {'ner': 0.00021567282210104997}\n",
      "Losses {'ner': 0.0006591434526057683}\n",
      "Losses {'ner': 0.0016065232175669613}\n",
      "Losses {'ner': 0.0016088005264955057}\n",
      "Losses {'ner': 5.091428886667613}\n",
      "Losses {'ner': 5.091489950034973}\n",
      "Losses {'ner': 0.0009759435376211586}\n",
      "Losses {'ner': 1.757259243389824}\n",
      "Losses {'ner': 1.7572675549886243}\n",
      "Losses {'ner': 1.7572675738315935}\n",
      "Losses {'ner': 2.1962500502958893e-07}\n",
      "Losses {'ner': 3.7182980167581835e-07}\n",
      "Losses {'ner': 1.9997570639528794}\n",
      "Losses {'ner': 1.999757064241544}\n",
      "Losses {'ner': 6.256064245951931e-07}\n",
      "Losses {'ner': 9.411749165333383e-05}\n",
      "Losses {'ner': 0.011349928430455236}\n",
      "Losses {'ner': 0.011349942677143794}\n",
      "Losses {'ner': 1.0564940245967591}\n",
      "Losses {'ner': 1.0564951116125243}\n",
      "Losses {'ner': 1.056501412470785}\n",
      "Losses {'ner': 1.0565014125453909}\n",
      "Losses {'ner': 0.00012128537122608189}\n",
      "Losses {'ner': 0.33653358060468436}\n",
      "Losses {'ner': 0.33653358429495156}\n",
      "Losses {'ner': 3.394139327703253}\n",
      "Losses {'ner': 0.18179576560431407}\n",
      "Losses {'ner': 0.18183552981783835}\n",
      "Losses {'ner': 0.18183626532313615}\n",
      "Losses {'ner': 0.18183626582752854}\n",
      "Losses {'ner': 1.3693713194111792e-06}\n",
      "Losses {'ner': 2.717248699184681e-06}\n",
      "Losses {'ner': 0.00017882391638848662}\n",
      "Losses {'ner': 0.803172007155677}\n",
      "Losses {'ner': 1.1555841769087492e-06}\n",
      "Losses {'ner': 3.880060380878191e-06}\n",
      "Losses {'ner': 1.1040664653836008}\n",
      "Losses {'ner': 1.104067159464139}\n",
      "Losses {'ner': 0.504775908720215}\n",
      "Losses {'ner': 0.5047760409233466}\n",
      "Losses {'ner': 0.5047816385734994}\n",
      "Losses {'ner': 0.5047816387472889}\n",
      "Losses {'ner': 3.17073775750038e-06}\n",
      "Losses {'ner': 2.074713886765524}\n",
      "Losses {'ner': 2.074829692754574}\n",
      "Losses {'ner': 2.617430376633124}\n",
      "Losses {'ner': 2.705095848155475}\n",
      "Losses {'ner': 2.705787861071739}\n",
      "Losses {'ner': 2.7057900500073524}\n",
      "Losses {'ner': 2.7057922946104087}\n",
      "Losses {'ner': 1.4979393370140315e-07}\n",
      "Losses {'ner': 2.533543484238565e-05}\n",
      "Losses {'ner': 0.05462788516418092}\n",
      "Losses {'ner': 0.05462877418895939}\n",
      "Losses {'ner': 3.1273041135870816e-08}\n",
      "Losses {'ner': 2.2433126160392787}\n",
      "Losses {'ner': 2.2433311953424053}\n",
      "Losses {'ner': 2.2433398281833465}\n",
      "Losses {'ner': 1.2901677875227668e-08}\n",
      "Losses {'ner': 2.4781916601481953e-07}\n",
      "Losses {'ner': 1.8735752778709507}\n",
      "Losses {'ner': 1.873575278346027}\n",
      "Losses {'ner': 1.8695102401529093e-07}\n",
      "Losses {'ner': 0.00014074583159352045}\n",
      "Losses {'ner': 1.0721186308618595}\n",
      "Losses {'ner': 1.0721186308664359}\n",
      "Losses {'ner': 6.154305364110269e-08}\n",
      "Losses {'ner': 0.16644719547030318}\n",
      "Losses {'ner': 0.16650618427772493}\n",
      "Losses {'ner': 0.16650623259571312}\n",
      "Losses {'ner': 2.763765282251529e-05}\n",
      "Losses {'ner': 3.2134616430971034e-05}\n",
      "Losses {'ner': 1.822718792225521}\n",
      "Losses {'ner': 1.822718792305972}\n",
      "Losses {'ner': 1.3665962392828135e-06}\n",
      "Losses {'ner': 1.0682436555546626e-05}\n",
      "Losses {'ner': 0.0028157437743796462}\n",
      "Losses {'ner': 0.002815743794776647}\n",
      "Losses {'ner': 3.0257181611943046e-05}\n",
      "Losses {'ner': 0.2632487108388075}\n",
      "Losses {'ner': 0.26324932723466404}\n",
      "Losses {'ner': 0.2632493272351028}\n",
      "Losses {'ner': 0.00018884313750833215}\n",
      "Losses {'ner': 0.00022381483555022896}\n",
      "Losses {'ner': 1.12912517412056}\n",
      "Losses {'ner': 1.1291260689229343}\n",
      "Losses {'ner': 3.9948648725363295e-07}\n",
      "Losses {'ner': 0.0007414223672410924}\n",
      "Losses {'ner': 1.7756970775778704}\n",
      "Losses {'ner': 1.775697416161782}\n",
      "Losses {'ner': 9.372475133788876e-07}\n",
      "Losses {'ner': 2.0214846122362675}\n",
      "Losses {'ner': 2.021574553998498}\n",
      "Losses {'ner': 2.0215745546686126}\n",
      "Losses {'ner': 0.0014301471467329657}\n",
      "Losses {'ner': 0.0014308021735311843}\n",
      "Losses {'ner': 0.0581745325769427}\n",
      "Losses {'ner': 0.05969115088408148}\n",
      "Losses {'ner': 1.2362096302982002e-06}\n",
      "Losses {'ner': 1.3833131916638841e-06}\n",
      "Losses {'ner': 2.016467182137077}\n",
      "Losses {'ner': 2.0164673254857166}\n",
      "Losses {'ner': 0.00017008124148508853}\n",
      "Losses {'ner': 1.7148650600750783}\n",
      "Losses {'ner': 1.7148697458978805}\n",
      "Losses {'ner': 1.7148697458979083}\n",
      "Losses {'ner': 8.44898831209339e-08}\n",
      "Losses {'ner': 0.4332897468499222}\n",
      "Losses {'ner': 0.43329192680044026}\n",
      "Losses {'ner': 0.43329192680732737}\n",
      "Losses {'ner': 0.00010913564294133928}\n",
      "Losses {'ner': 0.0001685408746127698}\n",
      "Losses {'ner': 3.515553074370706}\n",
      "Losses {'ner': 3.515553074390519}\n",
      "Losses {'ner': 9.618639384978422e-07}\n",
      "Losses {'ner': 1.989422792537261}\n",
      "Losses {'ner': 4.002137291727656}\n",
      "Losses {'ner': 4.002137291727726}\n",
      "Losses {'ner': 0.9055652011347253}\n",
      "Losses {'ner': 0.9055652607184033}\n",
      "Losses {'ner': 0.9055655790478069}\n",
      "Losses {'ner': 0.9055655801891946}\n",
      "Losses {'ner': 2.4545035749005604}\n",
      "Losses {'ner': 2.454503758701244}\n",
      "Losses {'ner': 2.454503813302973}\n",
      "Losses {'ner': 2.454503813417926}\n",
      "Losses {'ner': 8.995359640659624e-05}\n",
      "Losses {'ner': 8.998665478389205e-05}\n",
      "Losses {'ner': 1.967588312941399}\n",
      "Losses {'ner': 1.9675889917391307}\n",
      "Losses {'ner': 1.9544257637771807}\n",
      "Losses {'ner': 1.9544437684352773}\n",
      "Losses {'ner': 1.954443786069345}\n",
      "Losses {'ner': 1.9544438588452189}\n",
      "Losses {'ner': 4.837969535607229e-09}\n",
      "Losses {'ner': 0.5085083816282375}\n",
      "Losses {'ner': 0.510495426598402}\n",
      "Losses {'ner': 0.5104954266154058}\n",
      "Losses {'ner': 0.0004991064329471973}\n",
      "Losses {'ner': 0.9182632820798273}\n",
      "Losses {'ner': 0.9200114023683381}\n",
      "Losses {'ner': 0.9200114066260379}\n",
      "Losses {'ner': 0.0003049807938655391}\n",
      "Losses {'ner': 2.105084748227925}\n",
      "Losses {'ner': 2.1050849537560636}\n",
      "Losses {'ner': 2.1050849549403736}\n",
      "Losses {'ner': 0.2591244381198192}\n",
      "Losses {'ner': 0.2591269966861521}\n",
      "Losses {'ner': 0.2591278869022397}\n",
      "Losses {'ner': 0.25912788843884693}\n",
      "Losses {'ner': 1.839406437084405}\n",
      "Losses {'ner': 1.839420976735494}\n",
      "Losses {'ner': 1.8394212148748896}\n",
      "Losses {'ner': 1.839421502027887}\n",
      "Losses {'ner': 1.7594953634034027}\n",
      "Losses {'ner': 1.7594954901862188}\n",
      "Losses {'ner': 1.8164387488954998}\n",
      "Losses {'ner': 1.8164387506552788}\n",
      "Losses {'ner': 8.529631331065076e-06}\n",
      "Losses {'ner': 1.1612793865454748e-05}\n",
      "Losses {'ner': 1.1626209524071589e-05}\n",
      "Losses {'ner': 1.3161980689636925e-05}\n",
      "Losses {'ner': 4.9638095003194564}\n",
      "Losses {'ner': 4.963809579590564}\n",
      "Losses {'ner': 4.963810836300188}\n",
      "Losses {'ner': 4.963810837577919}\n",
      "Losses {'ner': 3.6086268076614942}\n",
      "Losses {'ner': 3.6086492382778137}\n",
      "Losses {'ner': 3.7064339239976936}\n",
      "Losses {'ner': 3.7064339239979054}\n",
      "Losses {'ner': 2.6012038695788497e-06}\n",
      "Losses {'ner': 8.38528945469319e-05}\n",
      "Losses {'ner': 3.3116083055747856}\n",
      "Losses {'ner': 3.311608305578879}\n",
      "Losses {'ner': 0.06512848634977508}\n",
      "Losses {'ner': 1.4722640567437915}\n",
      "Losses {'ner': 1.4741026120595082}\n",
      "Losses {'ner': 1.4741026351530955}\n",
      "Losses {'ner': 0.00010034753472611818}\n",
      "Losses {'ner': 0.8065451494598312}\n",
      "Losses {'ner': 0.8065451511928985}\n",
      "Losses {'ner': 0.8065451512312763}\n",
      "Losses {'ner': 0.09226562585763531}\n",
      "Losses {'ner': 1.6569688574888237}\n",
      "Losses {'ner': 1.6569690206758576}\n",
      "Losses {'ner': 1.65696902074676}\n",
      "Losses {'ner': 2.129057016393454e-05}\n",
      "Losses {'ner': 3.8225151755145194e-05}\n",
      "Losses {'ner': 1.9962916037547647}\n",
      "Losses {'ner': 1.996291609477423}\n"
     ]
    }
   ],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(50):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequoia Shareholders ORG\n",
      "Clients ORG\n",
      "Sequoia Fund ORG\n",
      "Material ORG\n",
      "Electronic Arts ORG\n",
      "Koninklijke Vopak ORG\n",
      "Vopak ORG\n",
      "While ORG\n",
      "Though ORG\n",
      "Reversing ORG\n",
      "Rather ORG\n",
      "The Fundâ€™s 1-year ORG\n",
      "5-year ORG\n",
      "March 31 ORG\n",
      "Current ORG\n",
      "Performance ORG\n",
      "DST Systems ORG\n",
      "57th Street ORG\n",
      "Suite ORG\n",
      "New York ORG\n",
      "NY ORG\n",
      "Tel ORG\n",
      "Ruane Cunniff ORG\n",
      "Please ORG\n",
      "Because ORG\n",
      "December 31 ORG\n",
      "Investor Day ORG\n",
      "Friday ORG\n",
      "May 17 ORG\n",
      "10:00 ORG\n",
      "the Grand Ballroom ORG\n",
      "Plaza ORG\n",
      "Hotel ORG\n",
      "Ruane Cunniff ORG\n",
      "Sincerely ORG\n",
      "The Ruane Cunniff Investment Committee ORG\n",
      "Arman Gokgol ORG\n",
      "Kline ORG\n",
      "Trevor Magyar ORG\n",
      "Chase Sheridan ORG\n",
      "Suite ORG\n",
      "New York ORG\n",
      "NY ORG\n",
      "Tel ORG\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(df.content[4])\n",
    "for ent in doc.ents:\n",
    "    if (ent.label_ == 'ORG'):\n",
    "        print(ent.text,ent.label_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2=spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Getting the ner component\n",
    "ner=nlp.get_pipe('ner')\n",
    "\n",
    "LABEL = \"SECTOR\"\n",
    "TRAIN_DATA =[ (\"Ucar is the world's leading manufacturer of graphite electrodes\", {\"entities\": [(43, 63, \"SECTOR\")]}),\n",
    "              (\"Chargeurs processes and trades in wool and produces fabrics\", {\"entities\": [(52, 59, \"SECTOR\")]}),\n",
    "              (\"Lambert Fenchurch is a publicly traded insurance broker in the U.K\", {\"entities\": [(39,48, \"SECTOR\")]}),\n",
    "              (\"Tencent operates China's dominant social media platform\", {\"entities\": [(34,46, \"SECTOR\")]}),\n",
    "              (\"A large interest in U.S cable company Charter Communications\", {\"entities\": [(23,28, \"SECTOR\")]}),\n",
    "              (\"Salesforce is a SaaS company\", {\"entities\": [(16,20, \"SECTOR\")]})]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
